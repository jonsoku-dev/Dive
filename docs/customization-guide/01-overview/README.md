# Dive 프로젝트 개요

Dive는 Function Calling 기능을 지원하는 모든 LLM 모델과 원활하게 통합되는 오픈소스 데스크톱 애플리케이션입니다. Model Context Protocol(MCP)을 통해 AI 에이전트가 외부 도구를 사용할 수 있도록 지원하여 강력한 기능 확장성을 제공합니다.

## 핵심 기능

### 다양한 LLM 지원
- **지원 모델**: ChatGPT, Claude(Anthropic), Ollama, Mistral AI, Google Gemini 등
- **호환성**: OpenAI 호환 API를 통한 다양한 모델 연결
- **자체 호스팅**: Ollama 및 기타 자체 호스팅 모델 지원

### 크로스 플랫폼 지원
- **Windows**: .exe 설치 파일 제공, Python 및 Node.js 환경 포함
- **macOS**: .dmg 설치 파일 제공
- **Linux**: AppImage 형식 지원

### MCP(Model Context Protocol) 지원
- **stdio 모드**: 표준 입출력을 통한 통신
- **SSE 모드**: Server-Sent Events를 통한 실시간 통신
- **확장성**: 다양한 외부 도구 통합 가능

### 다국어 지원
- **지원 언어**: 영어, 중국어(번체/간체), 일본어, 스페인어
- **i18n**: i18next를 통한 체계적인 다국어 관리

### 고급 API 관리
- **다중 API 키**: 여러 API 키 관리 및 전환 기능
- **모델 스위칭**: 대화 중 다른 모델로 전환 기능
- **매개변수 조정**: 온도, 토큰 제한 등 세부 매개변수 제어

### 커스텀 시스템 프롬프트
- **사용자 정의**: 사용자 지정 시스템 프롬프트 설정
- **저장 기능**: 여러 프롬프트 템플릿 저장 및 관리
- **컨텍스트 제어**: 대화 컨텍스트 길이 및 관리 기능

### 자동 업데이트 메커니즘
- **버전 확인**: 자동 업데이트 확인
- **다운로드 및 설치**: 배경에서 업데이트 다운로드 및 설치

## 아키텍처 개요

Dive는 크게 세 가지 주요 부분으로 구성됩니다:

1. **Electron 데스크톱 애플리케이션**: 사용자 인터페이스와 시스템 통합
2. **백엔드 서비스**: LLM 연결, MCP 서버 관리, 데이터베이스 처리
3. **MCP 도구 생태계**: AI가 사용할 수 있는 다양한 외부 도구

이 아키텍처는 확장 가능하고 유연하게 설계되어 기업 요구사항에 맞춘 커스터마이징이 용이합니다.

## 커스터마이징 개요

Dive 프로젝트의 포크 및 커스터마이징을 위한 주요 접근 방식:

- **UI 테마 및 브랜딩**: 회사 브랜드에 맞는 시각적 스타일링
- **커스텀 MCP 도구**: 내부 시스템 및 API와 통합
- **인증 시스템**: SSO 또는 기업 인증 시스템 통합
- **기업 특화 기능**: 팀 협업, 대화 공유, 관리 기능
- **보안 강화**: 기업 보안 요구사항에 맞는 데이터 처리

각 영역에 대한 자세한 커스터마이징 방법은 뒤에 이어지는 문서에서 상세히 다룹니다.
